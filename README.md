# Knowledge Graph Construction using Named Entity Recognition (NER)

This repository contains a **Knowledge Graph Construction** pipeline using **Named Entity Recognition (NER)**. It extracts entities from text, builds a knowledge graph, and provides tools for data scraping and text processing.

## ğŸ“Œ Project Overview
The goal of this project is to extract relationships between named entities from text data and represent them as a **Knowledge Graph**. This is achieved using:
- **NER models** (custom biomedical models from `Bio_Epidemiology_NER`)
- **Graph representation with NetworkX**
- **Text scraping & preprocessing utilities**

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/muditbaid/Semantic-Knowledge-Graph-from-Covid-ResearchCorpus.git
cd Semantic-Knowledge-Graph-from-Covid-ResearchCorpus
```

### 2ï¸âƒ£ Install Dependencies
Create a virtual environment and install required libraries:
```bash
python -m venv env
source env/bin/activate  # On Windows use `env\Scripts\activate`
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Pipeline
You can use the provided scripts to:
- Process text with NER
- Build a knowledge graph
- Scrape data from the web

#### **Run Named Entity Recognition (NER) on Sample Texts**
```python
from src.ner_pipeline import process_text

sample_texts = ["COVID-19 has impacted global healthcare systems."]
ner_results = process_text(sample_texts)
print(ner_results.head())
```

#### **Build & Visualize the Knowledge Graph**
```python
from src.graph_builder import build_knowledge_graph, visualize_graph

knowledge_graph = build_knowledge_graph(ner_results)
visualize_graph(knowledge_graph)
```

#### **Scrape Text from a Website**
```python
from src.scraper import scrape_text

sample_url = "https://en.wikipedia.org/wiki/Artificial_intelligence"
scraped_text = scrape_text(sample_url)
print(scraped_text[:500])
```

## ğŸ“‚ Repository Structure
```
.
â”œâ”€â”€ data/                 # Contains sample text data (if available)
â”œâ”€â”€ src/                  # Core scripts
â”‚   â”œâ”€â”€ ner_pipeline.py   # Named Entity Recognition pipeline
â”‚   â”œâ”€â”€ graph_builder.py  # Builds & visualizes the knowledge graph
â”‚   â”œâ”€â”€ scraper.py        # Web scraping for text data
â”‚   â”œâ”€â”€ utils.py          # Helper functions
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”‚   â”œâ”€â”€ knowledge_graph.ipynb   # Notebook for NER and Knowledge Graph 
â”œâ”€â”€ results/              # Stores generated knowledge graphs & reports
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ .gitignore            # Ignore unnecessary files
â””â”€â”€ .gitattributes        # If using Git LFS for large files
```

## ğŸ› ï¸ Future Improvements
- Use **TF-IDF vectorization** for better entity extraction.
- Fine-tune hyperparameters for **higher accuracy**.
- Improve graph relationship extraction with **dependency parsing**.

## ğŸ“Œ References
- [SpaCy NER](https://spacy.io/usage/linguistic-features#named-entities)
- [NetworkX Graphs](https://networkx.org/)
- [BeautifulSoup for Scraping](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

## ğŸ“ License
This project is for educational purposes. Free to use with attribution.

---
Feel free to contribute by submitting a pull request! ğŸš€

